// supabase/functions/migrate-to-consolidated-repos/index.ts

import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { encode } from "https://deno.land/std@0.168.0/encoding/base64.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    // 1. Authenticate user
    const supabaseUserClient = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_ANON_KEY') ?? '',
      { global: { headers: { Authorization: req.headers.get('Authorization')! } } }
    );
    const { data: { user } } = await supabaseUserClient.auth.getUser();
    if (!user) throw new Error("User not authenticated.");

    const { workspaceId, githubToken, workspaceName } = await req.json();
    if (!workspaceId || !githubToken || !workspaceName) {
      throw new Error("Missing required parameters: workspaceId, githubToken, workspaceName.");
    }

    const supabaseAdmin = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    );

    // 2. Create the consolidated workspace repository
    const repoName = `${workspaceName.toLowerCase().replace(/\s+/g, '-')}-workflows`;
    let attempt = 0;
    let currentRepoName = repoName;
    let workspaceRepoData = null;

    while (workspaceRepoData === null) {
      if (attempt > 0) { currentRepoName = `${repoName}-${attempt}`; }
      
      const githubResponse = await fetch('https://api.github.com/user/repos', {
        method: 'POST',
        headers: { 
          'Content-Type': 'application/json', 
          'Authorization': `token ${githubToken}`, 
          'Accept': 'application/vnd.github.v3+json' 
        },
        body: JSON.stringify({ 
          name: currentRepoName, 
          description: `Consolidated workflow repository for ${workspaceName}`, 
          private: true 
        }),
      });

      if (githubResponse.ok) {
        workspaceRepoData = await githubResponse.json();
      } else if (githubResponse.status === 422) {
        const errorBody = await githubResponse.json();
        if (errorBody.errors?.some((e: any) => e.message.includes('name already exists'))) {
          attempt++;
        } else { 
          throw new Error(`GitHub API Error: ${errorBody.message}`); 
        }
      } else {
        const errorBody = await githubResponse.json();
        throw new Error(`GitHub API Error: ${errorBody.message}`);
      }
      
      if (attempt > 10) throw new Error("Could not find an available repository name.");
    }

    const owner = workspaceRepoData.owner.login;
    const repo = workspaceRepoData.name;

    // 3. Create initial README
    const readmeContent = `# ${workspaceName} Workflows

This repository contains all workflow automations for the ${workspaceName} workspace.

## Structure

\`\`\`
workflows/
├── workflow-name-1/
│   ├── definition.json       # Main workflow definition
│   └── deployments/          # Client-specific deployment configurations
│       ├── client-a.json
│       └── client-b.json
├── workflow-name-2/
│   ├── definition.json
│   └── deployments/
└── ...
\`\`\`

## Workflow Management

- Each workflow has its own folder under \`workflows/\`
- The \`definition.json\` contains the master workflow configuration
- Client deployments are stored as separate files in the \`deployments/\` subfolder
- Version history is maintained through Git commits

Generated by Stencil Flow on ${new Date().toISOString()}
`;

    const readmeEncoded = encode(readmeContent);
    await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/README.md`, {
      method: 'PUT',
      headers: { 
        'Content-Type': 'application/json', 
        'Authorization': `token ${githubToken}`, 
        'Accept': 'application/vnd.github.v3+json' 
      },
      body: JSON.stringify({ 
        message: 'Initial commit: Add README', 
        content: readmeEncoded 
      }),
    });

    // 4. Update workspace with consolidated repo URL
    await supabaseAdmin
      .from('workspaces')
      .update({ git_repository: workspaceRepoData.html_url })
      .eq('id', workspaceId);

    // 5. Get all automations for this workspace
    const { data: automations } = await supabaseAdmin
      .from('automations')
      .select('id, name, description, workflow_json, git_repository')
      .eq('workspace_id', workspaceId);

    if (!automations || automations.length === 0) {
      return new Response(JSON.stringify({ 
        message: 'Workspace repository created successfully. No automations to migrate.',
        repositoryUrl: workspaceRepoData.html_url
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        status: 200,
      });
    }

    // 6. Migrate each automation to the new structure
    const migrationResults = [];
    
    for (const automation of automations) {
      const workflowFolderName = automation.name.toLowerCase().replace(/\s+/g, '-');
      const workflowPath = `workflows/${workflowFolderName}`;
      
      try {
        // Create workflow definition file
        const definitionContent = JSON.stringify(automation.workflow_json, null, 2);
        const definitionEncoded = encode(definitionContent);
        
        await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${workflowPath}/definition.json`, {
          method: 'PUT',
          headers: { 
            'Content-Type': 'application/json', 
            'Authorization': `token ${githubToken}`, 
            'Accept': 'application/vnd.github.v3+json' 
          },
          body: JSON.stringify({ 
            message: `Migrate workflow: ${automation.name}`, 
            content: definitionEncoded 
          }),
        });

        // Create deployments folder with placeholder
        const deploymentsReadme = `# Deployments for ${automation.name}

This folder contains client-specific deployment configurations for the ${automation.name} workflow.
`;
        const deploymentsReadmeEncoded = encode(deploymentsReadme);
        
        await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${workflowPath}/deployments/README.md`, {
          method: 'PUT',
          headers: { 
            'Content-Type': 'application/json', 
            'Authorization': `token ${githubToken}`, 
            'Accept': 'application/vnd.github.v3+json' 
          },
          body: JSON.stringify({ 
            message: `Create deployments folder for ${automation.name}`, 
            content: deploymentsReadmeEncoded 
          }),
        });

        // Update automation record with new workflow path
        await supabaseAdmin
          .from('automations')
          .update({ 
            workflow_path: workflowPath,
            git_repository: workspaceRepoData.html_url // Update to point to consolidated repo
          })
          .eq('id', automation.id);

        migrationResults.push({
          automationId: automation.id,
          name: automation.name,
          workflowPath: workflowPath,
          status: 'migrated'
        });

      } catch (error) {
        migrationResults.push({
          automationId: automation.id,
          name: automation.name,
          status: 'failed',
          error: error instanceof Error ? error.message : 'Unknown error'
        });
      }
    }

    // 7. Migrate existing deployments
    const { data: deployments } = await supabaseAdmin
      .from('deployments')
      .select(`
        id,
        automation_id,
        client_id,
        n8n_workflow_id,
        deployed_commit_sha,
        git_branch,
        automations (name, workflow_path),
        clients (name)
      `)
      .in('automation_id', automations.map(a => a.id));

    if (deployments && deployments.length > 0) {
      for (const deployment of deployments) {
        const automation = deployment.automations as any;
        const client = deployment.clients as any;
        
        if (!automation?.workflow_path || !client?.name) continue;

        try {
          const clientFileName = client.name.toLowerCase().replace(/\s+/g, '-');
          const deploymentFilePath = `${automation.workflow_path}/deployments/${clientFileName}.json`;
          
          const deploymentConfig = {
            clientId: deployment.client_id,
            n8nWorkflowId: deployment.n8n_workflow_id,
            deployedCommitSha: deployment.deployed_commit_sha,
            deployedAt: new Date().toISOString(),
            status: 'active'
          };
          
          const deploymentContent = JSON.stringify(deploymentConfig, null, 2);
          const deploymentEncoded = encode(deploymentContent);
          
          await fetch(`https://api.github.com/repos/${owner}/${repo}/contents/${deploymentFilePath}`, {
            method: 'PUT',
            headers: { 
              'Content-Type': 'application/json', 
              'Authorization': `token ${githubToken}`, 
              'Accept': 'application/vnd.github.v3+json' 
            },
            body: JSON.stringify({ 
              message: `Migrate deployment: ${automation.name} for ${client.name}`, 
              content: deploymentEncoded 
            }),
          });

          // Update deployment record with file path
          await supabaseAdmin
            .from('deployments')
            .update({ deployment_file_path: deploymentFilePath })
            .eq('id', deployment.id);

        } catch (error) {
          console.error(`Failed to migrate deployment ${deployment.id}:`, error);
        }
      }
    }

    return new Response(JSON.stringify({ 
      message: 'Migration completed successfully!',
      repositoryUrl: workspaceRepoData.html_url,
      migratedAutomations: migrationResults.filter(r => r.status === 'migrated').length,
      failedMigrations: migrationResults.filter(r => r.status === 'failed').length,
      migrationDetails: migrationResults
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 200,
    });

  } catch (error) {
    console.error('Migration error:', error);
    return new Response(JSON.stringify({ 
      error: error instanceof Error ? error.message : 'Unknown error' 
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      status: 500,
    });
  }
})
